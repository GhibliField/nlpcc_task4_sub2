# 2018-nlpcc task4  子任务2 第四名 f1分数 0.929方案

训练使用网上的 fasttext 预先训练的词向量。 

模型参数全部随缘。就试了个学习率- - 0.0001 -> 0.001

融合模型：训练 10个模型  联合投票

# 训练注意的地方：

1 分开训练 先把 下面的句子的lstm + 和 上面的上下文lstm 一起训练。 之后loss稳定下来后 把下面的lstm 固定住 只训练上层lstm。 最后把所有lstm 固定住 再训练一遍词向量。

2 学习率调大点。 大力出奇迹

# 也许能提升分数的地方(没做 写完模型 就去看其他东西了 O(∩_∩)O！) 

1 模型没有利用到任何实体信息(官方是有提供的。我刚开始以为是给slot任务的- -)。 后来想了想 可以在词向量上 下点功夫。比如 再开个 几个维度 来标注下词向量的实体信息。

2 可以把adam 换成sgd 感觉 分数会更高

# 做过一些事情，结果分数反而下降

1 交上去的模型 后2份在模型的基础上做了一些正则匹配。结果 分数反而低了。 可能误杀了一些。

2 对数据做了一些增强，比如 替换 等等 分数下降

3 loss加了个L2正则化，下降

4 学习率调得低， 分数下降
